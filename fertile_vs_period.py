# -*- coding: utf-8 -*-
"""Fertile vs Period.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sIWv4CJvqJqjeCmmhwfpgNU5WME2T0I7
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import datetime
from sklearn import datasets
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn import metrics
from sklearn import preprocessing
from sklearn.model_selection import train_test_split

fertile = pd.read_csv('/content/sleep_score_fertile.csv')
fertile.head(10)

#Change Timestamp from object to datetime
fertile['timestamp'] = pd.to_datetime(fertile['timestamp'])
#Remove sleep_log_entry_id
# Dont need this column?
fertile.drop('sleep_log_entry_id', inplace=True, axis=1)
fertile.dtypes

feature_cols = ['overall_score','revitalization_score','duration_score','deep_sleep_in_minutes','resting_heart_rate','restlessness']
x = fertile[feature_cols]
y = fertile['fertile']
# Splitting into training and testing
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1) #70% training and 30% test

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(x_train,y_train)
y_pred = gnb.predict(x_test)
print(y_pred)

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
ac = accuracy_score(y_test,y_pred)
print(cm)

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

# Create Decision Tree Classifier Object
clf = DecisionTreeClassifier(max_depth=2) #increases accuaracy

# Train Decision Tree Classifier
clf = clf.fit(x_train, y_train)

# Predict the response for test dataset
y_predict = clf.predict(x_test)

from sklearn.metrics import classification_report
from sklearn.metrics import precision_recall_fscore_support
print(classification_report(y_test, y_predict))

from matplotlib import pyplot
importance = clf.feature_importances_
# summarize feature importance
for i,v in enumerate(importance):
 print('Feature: %0d, Score: %.5f' % (i,v))
# plot feature importance
pyplot.bar([x for x in range(len(importance))], importance)
pyplot.show()

period = pd.read_csv('/content/sleep_score_fertile.csv')
#Change Timestamp from object to datetime
period['timestamp'] = pd.to_datetime(period['timestamp'])
#Remove sleep_log_entry_id
# Dont need this column?
period.drop('sleep_log_entry_id', inplace=True, axis=1)
period.dtypes

feature_cols = ['overall_score','revitalization_score','duration_score','deep_sleep_in_minutes','resting_heart_rate','restlessness']
x = period[feature_cols]
y = period['period']
# Splitting into training and testing
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1) #70% training and 30% test

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(x_train,y_train)
y_pred = gnb.predict(x_test)
print(y_pred)

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
ac = accuracy_score(y_test,y_pred)
print(cm)

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

# Create Decision Tree Classifier Object
clf = DecisionTreeClassifier(max_depth=2) #increases accuaracy

# Train Decision Tree Classifier
clf = clf.fit(x_train, y_train)

# Predict the response for test dataset
y_predict = clf.predict(x_test)

from sklearn.metrics import classification_report
from sklearn.metrics import precision_recall_fscore_support
print(classification_report(y_test, y_predict))

from matplotlib import pyplot
importance = clf.feature_importances_
# summarize feature importance
for i,v in enumerate(importance):
 print('Feature: %0d, Score: %.5f' % (i,v))
# plot feature importance
pyplot.bar([x for x in range(len(importance))], importance)
pyplot.show()

neither = pd.read_csv('/content/sleep_score_fertile.csv')
#Change Timestamp from object to datetime
neither['timestamp'] = pd.to_datetime(neither['timestamp'])
#Remove sleep_log_entry_id
# Dont need this column?
neither.drop('sleep_log_entry_id', inplace=True, axis=1)
neither.dtypes

feature_cols = ['overall_score','revitalization_score','duration_score','deep_sleep_in_minutes','resting_heart_rate','restlessness']
x = neither[feature_cols]
y = neither['neither']
# Splitting into training and testing
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1) #70% training and 30% test

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(x_train,y_train)
y_pred = gnb.predict(x_test)
print(y_pred)

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
ac = accuracy_score(y_test,y_pred)
print(cm)

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

# Create Decision Tree Classifier Object
clf = DecisionTreeClassifier(max_depth=2) #increases accuaracy

# Train Decision Tree Classifier
clf = clf.fit(x_train, y_train)

# Predict the response for test dataset
y_predict = clf.predict(x_test)

from sklearn.metrics import classification_report
from sklearn.metrics import precision_recall_fscore_support
print(classification_report(y_test, y_predict))

from matplotlib import pyplot
importance = clf.feature_importances_
# summarize feature importance
for i,v in enumerate(importance):
 print('Feature: %0d, Score: %.5f' % (i,v))
# plot feature importance
pyplot.bar([x for x in range(len(importance))], importance)
pyplot.show()