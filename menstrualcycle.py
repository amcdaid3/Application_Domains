# -*- coding: utf-8 -*-
"""MenstrualCycle.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Imww_uMWIFJY7njEMKl9SF05EFJGyOPe
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import datetime
from sklearn import datasets
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn import metrics
from sklearn import preprocessing
from sklearn.model_selection import train_test_split

sleep_score_l = pd.read_csv('/content/sleep_score_labelled.csv')

sleep_score_l.head(10)

sleep_score_l.describe()

sleep_score_l.dtypes

#Change Timestamp from object to datetime
sleep_score_l['timestamp'] = pd.to_datetime(sleep_score_l['timestamp'])
sleep_score_l.dtypes

sleep_score_l.duplicated()

#Remove sleep_log_entry_id
# Dont need this column?
sleep_score_l.drop('sleep_log_entry_id', inplace=True, axis=1)
sleep_score_l.head(5)

sleep_score_l.isnull().any()

"""## Visualization

"""

plt.close();
sns.set_style('whitegrid');
sns.pairplot(sleep_score_l, hue='cycle_type', height=3);
plt.show()

"""## Label encoding

*   0 = period
*   1 = fertile
*   2 = none
"""

feature_cols = ['overall_score','revitalization_score','duration_score','deep_sleep_in_minutes','resting_heart_rate','restlessness']
x = sleep_score_l[feature_cols]
y = sleep_score_l['cycle_type']
x = pd.DataFrame(x)
y = pd.DataFrame(y)

# Splitting into training and testing
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1) #70% training and 30% test

x_test.isnull().sum()

"""## Feature Scaling

Mapping features onto the same scale


"""

cols = x_train.columns

from sklearn.preprocessing import RobustScaler
scaler = RobustScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.fit_transform(x_test)

x_train = pd.DataFrame(x_train, columns=[cols])
x_test = pd.DataFrame(x_test, columns=[cols])
x_train.head()

"""## Decision Trees

"""

# Create Decision Tree Classifier Object
clf = DecisionTreeClassifier(max_depth=2) #increases accuaracy

# Train Decision Tree Classifier
clf = clf.fit(x_train, y_train)

# Predict the response for test dataset
y_predict = clf.predict(x_test)

# Model Accuracy
print('Accuracy:', metrics.accuracy_score(y_test, y_predict))

# Creating confusion matrix
cm = confusion_matrix(y_test, y_predict)
print(cm)

from sklearn.metrics import classification_report
from sklearn.metrics import precision_recall_fscore_support
print(classification_report(y_test, y_predict))

# Applying 5-Fold Cross Validation
from sklearn.model_selection import cross_val_score
scores = cross_val_score(clf, x_train, y_train, cv=5, scoring='accuracy')
print('Cross-validation scores:{}'.format(scores))

# We can summarize the cross validation accuracy by calculating its mean
# Compute Average cross-validation score

print('Average cross-validation score: {:.4f}'.format(scores.mean()))

from six import StringIO  
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus
dot_data = StringIO()
export_graphviz(clf, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True, feature_names = feature_cols,class_names=['0','1','2'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
graph.write_png('sleep_tree.png')
Image(graph.create_png())

"""## Decision Trees Feature importance

Using CART algorithm for Decision Tree classification 
"""

from matplotlib import pyplot
importance = clf.feature_importances_
# summarize feature importance
for i,v in enumerate(importance):
 print('Feature: %0d, Score: %.5f' % (i,v))
# plot feature importance
pyplot.bar([x for x in range(len(importance))], importance)
pyplot.show()

"""Feature 0 = overall_score

Feature 1 = revitilization_score

Feature 2 = duration_score

Feature 3 = deep_sleep_in_minutes

Feature 4 = resting_heart_rate

Feature 5 = restlessness

## KNN (k-nearest neighbours)
"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=4) ##started with 5 neighbours however 4 neighbours ideal
knn.fit(x_train, y_train)

knn_accuracy = knn.score(x_test, y_test)
print(knn_accuracy)

# Applying 5-Fold Cross Validation
from sklearn.model_selection import cross_val_score
scores = cross_val_score(knn, x_train, y_train, cv=5, scoring='accuracy')
print('Cross-validation scores:{}'.format(scores))

# We can summarize the cross validation accuracy by calculating its mean
# Compute Average cross-validation score

print('Average cross-validation score: {:.4f}'.format(scores.mean()))

"""## Naive Bayes Classifier"""

# Calculate Correlations
# Used to visualize the feature correlation matrix.
correlation = sleep_score_l.corr()
#plot the heatmap
sns.heatmap(correlation, xticklabels=correlation.columns,yticklabels=correlation.columns,annot=True)
# Plot the clustermap
# The cluster map shows the correlations as a hierarchically-clustered heatmap.
# Reading the clustermap to eliminate correlated features is easier
sns.clustermap(correlation, xticklabels=correlation.columns, yticklabels=correlation.columns, annot=True)

feature_cols = ['overall_score','revitalization_score','duration_score','deep_sleep_in_minutes','resting_heart_rate','restlessness']
x = sleep_score_l[feature_cols]
y = sleep_score_l['cycle_type']

# Splitting into training and testing
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1) #70% training and 30% test

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(x_train,y_train)
y_pred = gnb.predict(x_test)
print(y_pred)

# Accuracy calculations
from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
ac = accuracy_score(y_test,y_pred)
print(cm)

# Creating a dataframe for a array-formatted Confusion matrix, so it will be easy for plotting
cm_df = pd.DataFrame(cm,index=['menstruation','fertile','neither'], columns=['menstruation','fertile','neither'] )

#Plotting the confusion matrix
plt.figure(figsize=(5,4))
sns.heatmap(cm_df, annot=True)
plt.title('Confusion Matrix')
plt.ylabel('Actual Values')
plt.xlabel('Predict Values')
plt.show()

"""### Period

True Positive = 5

False Negative = 0+1 = 1

False Positive = 0+2 = 2

True Negative = 12+0+3+9 = 24

### Fertile

True Positive = 12

False Negative = 0+0 = 0

False Positive = 0+3 = 3

True Negative = 5+1+2+9 = 17
"""

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""### Check for overfitting and underfitting"""

print('Training set score: {:.4f}'.format(gnb.score(x_train, y_train)))
print('Training set score: {:.4f}'.format(gnb.score(x_test, y_test)))

"""These two values are quite comparable, so there is no sign of overfitting

### Compare model accuracy with null accuracy
"""

# Check class distribution in test set
y_test.value_counts()

"""The occurance of the most frequent class is 14, so we can calculate null accuracy by dividing 14 by total number of occurences."""

# Check null accuracy score
null_accuracy = (14/(2+14+12+6))
print('Null accuracy score: {0:0.4f}'.format(null_accuracy))

"""Conclude that our Gaussian Naive Bayes Classification model is doing a very good job in predicting the class labels

### k-Fold Cross Validation
"""

# Applying 5-Fold Cross Validation
from sklearn.model_selection import cross_val_score
scores = cross_val_score(gnb, x_train, y_train, cv=5, scoring='accuracy')
print('Cross-validation scores:{}'.format(scores))

# We can summarize the cross validation accuracy by calculating its mean
# Compute Average cross-validation score

print('Average cross-validation score: {:.4f}'.format(scores.mean()))

"""Our original accuracy was 0.81 but the mean cross-validation accuracy is 0.78. so the 5-fold cross validation accuracy does not result in performance improvement for this model.

looking at all the 5 scores produced by the 5-fold cross validation we can conclude that there is a relatively small variance in the accuracy between folds, we can conclude that the model is dependent of the particular folds used for training

### Removing overall_score from features as too correlated with the overall_score feature

Removing overall_score results in 0.78 accuracy

Removing duration_score results in a 0.72 accuracy
"""

feature_cols = ['duration_score','revitalization_score','deep_sleep_in_minutes','resting_heart_rate','restlessness']
x = sleep_score_l[feature_cols]
y = sleep_score_l['cycle_type']

# Splitting into training and testing
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1) #70% training and 30% test

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(x_train,y_train)
y_pred = gnb.predict(x_test)
print(classification_report(y_test, y_pred))

"""## Random Forest"""

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)
rf.fit(x_train, y_train)

predictions = rf.predict(x_test)
errors = abs(predictions - y_test)
print('Mean Absolute Error:', round(np.mean(errors),2), 'degrees.')

#Calculate the mean absolute persentage error (MAPE)
mape = 100 * (errors / y_test)

#Calculate and display accuracy
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')

"""## Gradient Boosting"""

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.preprocessing import MinMaxScaler

gbc = GradientBoostingClassifier(n_estimators=300,learning_rate=0.05,random_state=100,max_features=4)
gbc.fit(x_train,y_train)

# Confusion matrix
print(confusion_matrix(y_test, gbc.predict(x_test)))

# Accuracy of model
print('GBC accuracy is %2.2f' % accuracy_score(y_test, gbc.predict(x_test)))

# Classification report
from sklearn.metrics import classification_report
pred = gbc.predict(x_test)
print(classification_report(y_test, pred))

# Applying 5-Fold Cross Validation
from sklearn.model_selection import cross_val_score
scores = cross_val_score(gbc, x_train, y_train, cv=5, scoring='accuracy')
print('Cross-validation scores:{}'.format(scores))

# We can summarize the cross validation accuracy by calculating its mean
# Compute Average cross-validation score

print('Average cross-validation score: {:.4f}'.format(scores.mean()))

from xgboost import XGBClassifier
xgb_clf = XGBClassifier()
xgb_clf.fit(x_train, y_train)
score = xgb_clf.score(x_test, y_test)
print(score)

from sklearn.metrics import classification_report
pred = xgb_clf.predict(x_test)
print(classification_report(y_test, pred))

# Applying 5-Fold Cross Validation
from sklearn.model_selection import cross_val_score
scores = cross_val_score(xgb_clf, x_train, y_train, cv=5, scoring='accuracy')
print('Cross-validation scores:{}'.format(scores))

print('Average cross-validation score: {:.4f}'.format(scores.mean()))

"""## Only including certain features

Features available:


*   overall_score
*   composition_score
*   revitalization_score
*   duration_score
*   deep_sleep_in_minutes
*   resting_heart_rate
*   restlessness

Target:
*   cycle_type

## Naive Bayes Classifier revisited

from link: https://www.kaggle.com/code/prashant111/naive-bayes-classifier-in-python
"""

from sklearn.naive_bayes import GaussianNB

gnb = GaussianNB()

gnb.fit(x_train, y_train)

y_pred = gnb.predict(x_test)

from sklearn.metrics import accuracy_score

print('Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test,y_pred)))

"""## Clustering - K-means"""

from sklearn.cluster import KMeans
from matplotlib.colors import ListedColormap

colnames = list(sleep_score_l.columns[1:-1])

customcmap = ListedColormap(["crimson", "mediumblue", "darkmagenta"])

fig, ax = plt.subplots(figsize=(8, 6))
plt.scatter(x=sleep_score_l['overall_score'], y=sleep_score_l['deep_sleep_in_minutes'], s=150,
            c=sleep_score_l['cycle_type'].astype('category'), 
            cmap = customcmap)
ax.set_xlabel(r'x', fontsize=14)
ax.set_ylabel(r'y', fontsize=14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.show()

def initiate_centroids(k, dset):
    '''
    Select k data points as centroids
    k: number of centroids
    dset: pandas dataframe
    '''
    centroids = dset.sample(k)
    return centroids

np.random.seed(42)
k=3
df = sleep_score_l[['x','y']]
centroids = initiate_centroids(k, df)
centroids

